{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T12:43:08.172886Z",
     "iopub.status.busy": "2025-02-18T12:43:08.172029Z",
     "iopub.status.idle": "2025-02-18T12:43:11.765601Z",
     "shell.execute_reply": "2025-02-18T12:43:11.764275Z",
     "shell.execute_reply.started": "2025-02-18T12:43:08.172852Z"
    },
    "id": "0MlTmnOC86ZW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install accelerate>=0.20.1 transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T12:43:11.767322Z",
     "iopub.status.busy": "2025-02-18T12:43:11.767054Z",
     "iopub.status.idle": "2025-02-18T12:43:11.771703Z",
     "shell.execute_reply": "2025-02-18T12:43:11.770354Z",
     "shell.execute_reply.started": "2025-02-18T12:43:11.767299Z"
    },
    "id": "YAG5Udsz9Bzy",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abhyudya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T12:43:11.773292Z",
     "iopub.status.busy": "2025-02-18T12:43:11.773050Z",
     "iopub.status.idle": "2025-02-18T12:43:11.786346Z",
     "shell.execute_reply": "2025-02-18T12:43:11.785536Z",
     "shell.execute_reply.started": "2025-02-18T12:43:11.773272Z"
    },
    "id": "wgKCXKbp9Bxq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class KDTrainingArgs(TrainingArguments):\n",
    "  def __init__(self, *args, alpha=1, temperature = 0.2, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "    self.alpha = alpha\n",
    "    self.temperature = temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T12:43:11.787550Z",
     "iopub.status.busy": "2025-02-18T12:43:11.787304Z",
     "iopub.status.idle": "2025-02-18T12:43:27.601831Z",
     "shell.execute_reply": "2025-02-18T12:43:27.600893Z",
     "shell.execute_reply.started": "2025-02-18T12:43:11.787519Z"
    },
    "id": "jtpK-Y039Bva",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T12:43:27.603298Z",
     "iopub.status.busy": "2025-02-18T12:43:27.602774Z",
     "iopub.status.idle": "2025-02-18T12:43:27.609194Z",
     "shell.execute_reply": "2025-02-18T12:43:27.608223Z",
     "shell.execute_reply.started": "2025-02-18T12:43:27.603273Z"
    },
    "id": "f3pi65A_-47y",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class KDTrainer(Trainer):\n",
    "  def __init__(self, *args, teacher_model = None, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "    self.teacher_model = teacher_model\n",
    "\n",
    "\n",
    "  def loss(self, model, inputs, return_outputs = False):\n",
    "\n",
    "    student_outputs = model(**inputs)\n",
    "    ce_loss = student_outputs.loss\n",
    "    student_logits = student_outputs.logits\n",
    "\n",
    "    loss_fn = nn.KLDivLoss(reduction = 'batchmean')\n",
    "\n",
    "    kd_loss = self.args.temperature**2*loss_fn(\n",
    "        F.log_softmax(student_logits/self.args.temperature, dim = -1),\n",
    "        F.softmax(self.teacher_model(**inputs).logits/self.args.temperature, dim = -1)\n",
    "    )\n",
    "\n",
    "\n",
    "    loss = self.args.alpha*ce_loss + (1. -self.args.alpha)*kd_loss\n",
    "\n",
    "    return(loss, student_outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "execution": {
     "iopub.execute_input": "2025-02-18T12:47:17.903735Z",
     "iopub.status.busy": "2025-02-18T12:47:17.903382Z",
     "iopub.status.idle": "2025-02-18T12:47:18.734830Z",
     "shell.execute_reply": "2025-02-18T12:47:18.734031Z",
     "shell.execute_reply.started": "2025-02-18T12:47:17.903704Z"
    },
    "id": "iPHcBEtY-43p",
    "outputId": "bb6ac618-3ac0-4f88-fe52-f18bba1b7a96",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'what expression would i use to say i love you if i were an italian', 'intent': 61}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"clinc/clinc_oos\", 'plus')\n",
    "temp = ds['train'][0]\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T12:47:18.736157Z",
     "iopub.status.busy": "2025-02-18T12:47:18.735828Z",
     "iopub.status.idle": "2025-02-18T12:47:18.740978Z",
     "shell.execute_reply": "2025-02-18T12:47:18.740237Z",
     "shell.execute_reply.started": "2025-02-18T12:47:18.736132Z"
    },
    "id": "86T6PbVwEZ6l",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate\n"
     ]
    }
   ],
   "source": [
    "intents = ds['train'].features['intent']\n",
    "intent = intents.int2str(temp['intent'])\n",
    "print(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T12:47:18.742443Z",
     "iopub.status.busy": "2025-02-18T12:47:18.742202Z",
     "iopub.status.idle": "2025-02-18T12:47:18.753352Z",
     "shell.execute_reply": "2025-02-18T12:47:18.752489Z",
     "shell.execute_reply.started": "2025-02-18T12:47:18.742423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T12:47:18.754540Z",
     "iopub.status.busy": "2025-02-18T12:47:18.754264Z",
     "iopub.status.idle": "2025-02-18T12:47:18.868994Z",
     "shell.execute_reply": "2025-02-18T12:47:18.868040Z",
     "shell.execute_reply.started": "2025-02-18T12:47:18.754518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "student_ckpt = 'distilbert-base-uncased'\n",
    "student_tknzr = AutoTokenizer.from_pretrained(student_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T12:46:45.503353Z",
     "iopub.status.busy": "2025-02-18T12:46:45.503049Z",
     "iopub.status.idle": "2025-02-18T12:46:45.507394Z",
     "shell.execute_reply": "2025-02-18T12:46:45.506212Z",
     "shell.execute_reply.started": "2025-02-18T12:46:45.503330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return student_tknzr(batch['text'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T12:48:28.811603Z",
     "iopub.status.busy": "2025-02-18T12:48:28.811320Z",
     "iopub.status.idle": "2025-02-18T12:48:29.876906Z",
     "shell.execute_reply": "2025-02-18T12:48:29.876241Z",
     "shell.execute_reply.started": "2025-02-18T12:48:28.811582Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5500/5500 [00:00<00:00, 27381.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds_tokenized = ds.map(tokenize, batched = True, remove_columns = 'text').rename_column('intent', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:04:59.543924Z",
     "iopub.status.busy": "2025-02-18T13:04:59.543591Z",
     "iopub.status.idle": "2025-02-18T13:04:59.950295Z",
     "shell.execute_reply": "2025-02-18T13:04:59.949475Z",
     "shell.execute_reply.started": "2025-02-18T13:04:59.543887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import evaluate\n",
    "acc = evaluate.load('accuracy')\n",
    "\n",
    "def comp_metric(preds):\n",
    "    pred, labels = preds\n",
    "    pred = np.argmax(pred, axis = 1)\n",
    "    return acc.compute(predictions = pred, references = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:13:08.386899Z",
     "iopub.status.busy": "2025-02-18T13:13:08.386571Z",
     "iopub.status.idle": "2025-02-18T13:13:08.390766Z",
     "shell.execute_reply": "2025-02-18T13:13:08.389939Z",
     "shell.execute_reply.started": "2025-02-18T13:13:08.386871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batchsize = 48\n",
    "finetuned_student_ckpt = \"distilbert-base-uncased-finetuned-clinc-student\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:16:24.314586Z",
     "iopub.status.busy": "2025-02-18T13:16:24.314245Z",
     "iopub.status.idle": "2025-02-18T13:16:24.349008Z",
     "shell.execute_reply": "2025-02-18T13:16:24.348308Z",
     "shell.execute_reply.started": "2025-02-18T13:16:24.314556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sttrain_args = KDTrainingArgs(\n",
    "    output_dir = finetuned_student_ckpt, eval_strategy = 'epoch',\n",
    "    num_train_epochs = 10, learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = batchsize,\n",
    "    per_device_eval_batch_size = batchsize,\n",
    "    alpha = 1, weight_decay = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:16:40.704353Z",
     "iopub.status.busy": "2025-02-18T13:16:40.704022Z",
     "iopub.status.idle": "2025-02-18T13:16:44.514940Z",
     "shell.execute_reply": "2025-02-18T13:16:44.513783Z",
     "shell.execute_reply.started": "2025-02-18T13:16:40.704325Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abhyudya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Abhyudya\\.cache\\huggingface\\hub\\models--transformersbook--bert-base-uncased-finetuned-clinc. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
    "pipe = pipeline(\"text-classification\", model=bert_ckpt)\n",
    "\n",
    "id2label = pipe.model.config.id2label\n",
    "label2id = pipe.model.config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:19:54.990439Z",
     "iopub.status.busy": "2025-02-18T13:19:54.990028Z",
     "iopub.status.idle": "2025-02-18T13:19:55.037555Z",
     "shell.execute_reply": "2025-02-18T13:19:55.036953Z",
     "shell.execute_reply.started": "2025-02-18T13:19:54.990406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "num_labels = intents.num_classes\n",
    "student_config = (AutoConfig.from_pretrained(student_ckpt, num_labels = num_labels, id2label = id2label, label2id = label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:23:29.469346Z",
     "iopub.status.busy": "2025-02-18T13:23:29.469016Z",
     "iopub.status.idle": "2025-02-18T13:23:29.473893Z",
     "shell.execute_reply": "2025-02-18T13:23:29.472911Z",
     "shell.execute_reply.started": "2025-02-18T13:23:29.469321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def student_init():\n",
    "  return (AutoModelForSequenceClassification.from_pretrained(student_ckpt, config=student_config).to(device))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:23:40.370212Z",
     "iopub.status.busy": "2025-02-18T13:23:40.369892Z",
     "iopub.status.idle": "2025-02-18T13:23:40.373841Z",
     "shell.execute_reply": "2025-02-18T13:23:40.372976Z",
     "shell.execute_reply.started": "2025-02-18T13:23:40.370147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "teacher_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:23:55.076315Z",
     "iopub.status.busy": "2025-02-18T13:23:55.075983Z",
     "iopub.status.idle": "2025-02-18T13:23:55.540393Z",
     "shell.execute_reply": "2025-02-18T13:23:55.539141Z",
     "shell.execute_reply.started": "2025-02-18T13:23:55.076292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "teacher_model = (AutoModelForSequenceClassification\n",
    "                     .from_pretrained(teacher_ckpt, num_labels=num_labels)\n",
    "                     .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T13:25:51.475610Z",
     "iopub.status.busy": "2025-02-18T13:25:51.475282Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhyudya\\AppData\\Local\\Temp\\ipykernel_23564\\157823462.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `KDTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "c:\\Users\\Abhyudya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Abhyudya\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 05:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.218292</td>\n",
       "      <td>0.738387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.740400</td>\n",
       "      <td>1.606410</td>\n",
       "      <td>0.865161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.740400</td>\n",
       "      <td>0.802119</td>\n",
       "      <td>0.912581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.373400</td>\n",
       "      <td>0.475949</td>\n",
       "      <td>0.930645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.441200</td>\n",
       "      <td>0.344988</td>\n",
       "      <td>0.934516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.441200</td>\n",
       "      <td>0.300421</td>\n",
       "      <td>0.940645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.266686</td>\n",
       "      <td>0.942581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.257944</td>\n",
       "      <td>0.943226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.255009</td>\n",
       "      <td>0.943548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.255079</td>\n",
       "      <td>0.944194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3180, training_loss=0.9283622285854891, metrics={'train_runtime': 304.4594, 'train_samples_per_second': 500.888, 'train_steps_per_second': 10.445, 'total_flos': 827728372450224.0, 'train_loss': 0.9283622285854891, 'epoch': 10.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_trainer = KDTrainer(model_init=student_init,\n",
    "        teacher_model=teacher_model, args=sttrain_args,\n",
    "        train_dataset=ds_tokenized['train'], eval_dataset=ds_tokenized['validation'],\n",
    "        compute_metrics=comp_metric, tokenizer=student_tknzr)\n",
    "distilbert_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_teacher_model():\n",
    "  teacher_model.save_pretrained(\"teacher_model\")\n",
    "def save_student_model():\n",
    "  distilbert_trainer.save_model('student_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_teacher_model()\n",
    "save_student_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "import os\n",
    "\n",
    "def compute_parameters(model_path):\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "  parameters = model.num_parameters()\n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109598359"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tea_param = compute_parameters(\"teacher_model\")\n",
    "tea_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67069591"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu_param = compute_parameters(\"student_model\")\n",
    "stu_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage Reduction in Number of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.804201438818986"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tea_param-stu_param)/tea_param * 100"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
